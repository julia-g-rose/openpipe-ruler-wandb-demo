# Training configuration for email search agent
# This file defines all hyperparameters and settings for the training run

# Model configuration
# project: "julia-openpipe-wandb-email-agent-demo-v18"
project: "email-agent-pipeline-test"
base_model: "OpenPipe/Qwen3-14B-Instruct"

# Dataset configuration
training_dataset_size: 5  # Number of training scenarios to load
validation_dataset_size: 5  # Number of validation scenarios to load
dataset_seed: 42  # Random seed for dataset shuffling

# Dataset artifacts
training_dataset_artifact: "enron-training-scenarios:latest"
validation_dataset_artifact: "enron-validation-scenarios:latest"

# Judge models
ruler_judge_model: "openai/gpt-5"  # Used by RULER for scoring trajectories during training
correctness_judge_model: "openai/gpt-5"  # Used for evaluating answer correctness
tool_judge_model: "openai/gpt-5"  # Used for evaluating tool call appropriateness

# Comparison models (for compare_models.py)
comparison_model: "gpt-5"  # Second model for leaderboard comparison

# Training hyperparameters
groups_per_step: 2
num_epochs: 1
rollouts_per_group: 4
learning_rate: 1.0e-5

# Validation and evaluation
validation_step_interval: 1

# Checkpointing
save_checkpoint_artifact: true  # Save checkpoints as W&B artifacts

# Reproducibility
random_seed: 42

# W&B run configuration
wandb_run_name: "email-agent-training"
wandb_job_type: "train"

